{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from chinese_calendar import is_workday, is_holiday\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data10_in = pd.read_csv('../../data/data_10m_in.csv',index_col=[0])\n",
    "\n",
    "data10_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_seq(best_path, threshold=1):\n",
    "    com_ls = []\n",
    "    pre = best_path[0]\n",
    "    length = 1\n",
    "    for i, element in enumerate(best_path):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        cur = best_path[i]\n",
    "        if cur[0] == pre[0] + 1 and cur[1] == pre[1] + 1:\n",
    "            length = length + 1\n",
    "        else:\n",
    "            com_ls.append(length)\n",
    "            length = 1\n",
    "        pre = cur\n",
    "    com_ls.append(length)\n",
    "    return list(filter(lambda num: True if threshold < num else False, com_ls))\n",
    "\n",
    "\n",
    "def calculate_attenuate_weight(seqLen, com_ls):\n",
    "    weight = 0\n",
    "    for comlen in com_ls:\n",
    "        weight = weight + (comlen * comlen) / (seqLen * seqLen)\n",
    "    return 1 - math.sqrt(weight)\n",
    "\n",
    "\n",
    "def best_path(paths):\n",
    "    \"\"\"Compute the optimal path from the nxm warping paths matrix.\"\"\"\n",
    "    i, j = int(paths.shape[0] - 1), int(paths.shape[1] - 1)\n",
    "    p = []\n",
    "    if paths[i, j] != -1:\n",
    "        p.append((i - 1, j - 1))\n",
    "    while i > 0 and j > 0:\n",
    "        c = np.argmin([paths[i - 1, j - 1], paths[i - 1, j], paths[i, j - 1]])\n",
    "        if c == 0:\n",
    "            i, j = i - 1, j - 1\n",
    "        elif c == 1:\n",
    "            i = i - 1\n",
    "        elif c == 2:\n",
    "            j = j - 1\n",
    "        if paths[i, j] != -1:\n",
    "            p.append((i - 1, j - 1))\n",
    "    p.pop()\n",
    "    p.reverse()\n",
    "    return p\n",
    "\n",
    "\n",
    "def TimeSeriesSimilarity(s1, s2):\n",
    "    l1 = len(s1)\n",
    "    l2 = len(s2)\n",
    "    paths = np.full((l1 + 1, l2 + 1), np.inf)  # 全部赋予无穷大\n",
    "    paths[0, 0] = 0\n",
    "    for i in range(l1):\n",
    "        for j in range(l2):\n",
    "            d = s1[i] - s2[j]\n",
    "            cost = d ** 2\n",
    "            paths[i + 1, j + 1] = cost + min(paths[i, j + 1], paths[i + 1, j], paths[i, j])\n",
    "\n",
    "    paths = np.sqrt(paths)\n",
    "    s = paths[l1, l2]\n",
    "    return s, paths.T\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 测试数据\n",
    "    s1 = np.array([1, 2, 0, 1, 1, 2, 0, 1, 1, 2, 0, 1, 1, 2, 0, 1])\n",
    "    s2 = np.array([0, 1, 1, 2, 0, 1, 1, 2, 0, 1, 1, 2, 0, 1, 1, 2])\n",
    "    s3 = np.array([0.8, 1.5, 0, 1.2, 0, 0, 0.6, 1, 1.2, 0, 0, 1, 0.2, 2.4, 0.5, 0.4])\n",
    "\n",
    "    # 原始算法\n",
    "    distance12, paths12 = TimeSeriesSimilarity(s1, s2)\n",
    "    distance13, paths13 = TimeSeriesSimilarity(s1, s3)\n",
    "\n",
    "    print(\"更新前s1和s2距离：\" + str(distance12))\n",
    "    print(\"更新前s1和s3距离：\" + str(distance13))\n",
    "\n",
    "    best_path12 = best_path(paths12)\n",
    "    best_path13 = best_path(paths13)\n",
    "\n",
    "    # 衰减系数\n",
    "    com_ls1 = get_common_seq(best_path12)\n",
    "    com_ls2 = get_common_seq(best_path13)\n",
    "\n",
    "    # print(len(best_path12), com_ls1)\n",
    "    # print(len(best_path13), com_ls2)\n",
    "    weight12 = calculate_attenuate_weight(len(best_path12), com_ls1)\n",
    "    weight13 = calculate_attenuate_weight(len(best_path13), com_ls2)\n",
    "\n",
    "    # 更新距离\n",
    "    print(\"更新后s1和s2距离：\" + str(distance12 * weight12))\n",
    "    print(\"更新后s1和s3距离：\" + str(distance13 * weight13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data10_in.iloc[:,0].values.reshape(2808,1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "# x = np.array([[1,1], [2,2], [3,3], [4,4], [5,5]])\n",
    "# y = np.array([[2,2], [3,3], [4,4]])\n",
    "x = data10_in.iloc[:,0]\n",
    "y = data10_in.iloc[:,1]\n",
    "\n",
    "distance, path = fastdtw(x, y, dist=euclidean)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "# x = np.array([[1,1], [2,2], [3,3], [4,4], [5,5]])\n",
    "# y = np.array([[2,2], [3,3], [4,4]])\n",
    "x = data10_in.iloc[:,0]\n",
    "y = data10_in.iloc[:,1]\n",
    "\n",
    "distance, path = fastdtw(y, x, dist=euclidean)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sensors = 81\n",
    "dist_mx = np.zeros((num_sensors, num_sensors), dtype=np.float32)\n",
    "dist_mx[:] = 0\n",
    "dist_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(81):\n",
    "    x_id = i\n",
    "    x = data10_in.iloc[:,i]\n",
    "    for j in range(81):\n",
    "        y_id = j\n",
    "        y = data10_in.iloc[:,j]\n",
    "        distance, path = fastdtw(x, y, dist=euclidean)\n",
    "        dist_mx[x_id][y_id]=distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def cal(task,managed_dict, managed_locker):\n",
    "    dist_mx1 = np.zeros((num_sensors, num_sensors), dtype=np.float32)\n",
    "    dist_mx1[:] = 0\n",
    "    for i in range(81):\n",
    "        x_id = i\n",
    "        x = data10_in.iloc[:,i]\n",
    "        for j in range(task*3+j):\n",
    "            y_id = j\n",
    "            y = data10_in.iloc[:,j]\n",
    "            distance, path = fastdtw(x, y, dist=euclidean)\n",
    "            dist_mx1[x_id][y_id]=distance\n",
    "    return dist_mx1\n",
    "            \n",
    "\n",
    "# def train_on_parameter(name, param, result_dict, result_lock):\n",
    "#     result = 0\n",
    "#     for num in param:\n",
    "#         result += math.sqrt(num * math.tanh(num) / math.log2(num) / math.log10(num))\n",
    "#     with result_lock:\n",
    "#         result_dict[name] = result\n",
    "#     return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    start_t = datetime.datetime.now()\n",
    "\n",
    "    num_cores = int(mp.cpu_count())\n",
    "    print(\"本地计算机有: \" + str(num_cores) + \" 核心\")\n",
    "    pool = mp.Pool(num_cores-1)\n",
    "\n",
    "    manager = mp.Manager()\n",
    "    managed_locker = manager.Lock()\n",
    "    managed_dict = manager.dict()\n",
    "    results = [pool.apply_async(cal, args=(task, managed_dict, managed_locker)) for task in np.arange(0,27)]\n",
    "    results = [p.get() for p in results]\n",
    "\n",
    "    print(managed_dict)\n",
    "\n",
    "    end_t = datetime.datetime.now()\n",
    "    elapsed_sec = (end_t - start_t).total_seconds()\n",
    "    print(\"多线程计算 共消耗: \" + \"{:.2f}\".format(elapsed_sec) + \" 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def train_on_parameter(name, param, result_dict, result_lock):\n",
    "    result = 0\n",
    "    for num in param:\n",
    "        result += math.sqrt(num * math.tanh(num) / math.log2(num) / math.log10(num))\n",
    "    with result_lock:\n",
    "        result_dict[name] = result\n",
    "    return name\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    start_t = datetime.datetime.now()\n",
    "\n",
    "    num_cores = int(mp.cpu_count())\n",
    "    print(\"本地计算机有: \" + str(num_cores) + \" 核心\")\n",
    "    pool = mp.Pool(num_cores)\n",
    "    param_dict = {'task1': list(range(10, 30000000)),\n",
    "                  'task2': list(range(30000000, 60000000)),\n",
    "                  'task3': list(range(60000000, 90000000)),\n",
    "                  'task4': list(range(90000000, 120000000)),\n",
    "                  'task5': list(range(120000000, 150000000)),\n",
    "                  'task6': list(range(150000000, 180000000)),\n",
    "                  'task7': list(range(180000000, 210000000)),\n",
    "                  'task8': list(range(210000000, 240000000))}\n",
    "    manager = mp.Manager()\n",
    "    managed_locker = manager.Lock()\n",
    "    managed_dict = manager.dict()\n",
    "    results = [pool.apply_async(train_on_parameter, args=(name, param, managed_dict, managed_locker)) for name, param in param_dict.items()]\n",
    "    results = [p.get() for p in results]\n",
    "\n",
    "    print(managed_dict)\n",
    "\n",
    "    end_t = datetime.datetime.now()\n",
    "    elapsed_sec = (end_t - start_t).total_seconds()\n",
    "    print(\"多线程计算 共消耗: \" + \"{:.2f}\".format(elapsed_sec) + \" 秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def train_on_parameter(name, param):\n",
    "    result = 0\n",
    "    for num in param:\n",
    "        result += math.sqrt(num * math.tanh(num) / math.log2(num) / math.log10(num))\n",
    "    return name\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    start_t = datetime.datetime.now()\n",
    "\n",
    "    num_cores = int(mp.cpu_count())\n",
    "    print(\"本地计算机有: \" + str(num_cores) + \" 核心\")\n",
    "    pool = mp.Pool(num_cores)\n",
    "    param_dict = {'task1': list(range(10, 30000000)),\n",
    "                  'task2': list(range(30000000, 60000000)),\n",
    "                  'task3': list(range(60000000, 90000000)),\n",
    "                  'task4': list(range(90000000, 120000000)),\n",
    "                  'task5': list(range(120000000, 150000000)),\n",
    "                  'task6': list(range(150000000, 180000000)),\n",
    "                  'task7': list(range(180000000, 210000000)),\n",
    "                  'task8': list(range(210000000, 240000000))}\n",
    "    results = [pool.apply_async(train_on_parameter, args=(name, param)) for name, param in param_dict.items()]\n",
    "    results = [p.get() for p in results]\n",
    "\n",
    "    end_t = datetime.datetime.now()\n",
    "    elapsed_sec = (end_t - start_t).total_seconds()\n",
    "    print(\"多进程计算 共消耗: \" + \"{:.2f}\".format(elapsed_sec) + \" 秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.8",
   "language": "python",
   "name": "torch1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
